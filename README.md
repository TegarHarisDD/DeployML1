## Obesity Classification Web App

Welcome to the **Obesity Classification** Streamlit application! This repository contains everything you need to explore, predict, and understand obesity categories based on lifestyle and demographic data using three machine learning models: Kâ€‘Nearest Neighbors (KNN), Support Vector Machine (SVM), and XGBoost (XGB).

## ğŸ” Project Overview

This application allows users to:

* **Explore** dataset metadata and model performance.
* **Input** individual profiles to receive obesityâ€category predictions from three tuned models.
* **Bulkâ€predict** on CSV files using the XGBoost model and download results.

Our goal is to provide an intuitive interface for nonâ€‘technical users to leverage machine learning in assessing obesity levels, fostering awareness of lifestyle impacts on health.

---

## âœ¨ Features

1. **Threeâ€‘Page Streamlit Interface**

   * **About**: Detailed dataset overview, dataâ€‘cleaning steps, feature engineering, and tuned model accuracies.
   * **Single Prediction**: Enter personal and lifestyle information via humanâ€‘readable forms; view predictions from KNN, SVM, and XGBoost in category labels.
   * **Bulk Prediction**: Upload a CSV of multiple records and download a new CSV with predicted obesity categories (using XGBoost).

2. **Robust Preprocessing Pipeline**

   * Missingâ€value standardization, outlier removal (hard bounds + IQR), BMI feature engineering.
   * Label encoding for target and oneâ€‘hot encoding for categorical features.
   * Standard scaling of numeric features.
   * SMOTE for class balancing in training.

3. **Multiple Models with Hyperparameter Tuning**

   * KNN, SVM, XGBoost: All tuned via `GridSearchCV` for optimal performance.
   * Persisted scaler, feature list, label encoder, and models for reproducibility.

---

## ğŸ—„ï¸ Data Description

* **Samples**: 2,111
* **Features** (17):

  * Demographics: `Age`, `Gender`, `Height`, `Weight`
  * Dietary & Lifestyle: `CALC`, `FAVC`, `FCVC`, `NCP`, `SCC`, `SMOKE`, `CH2O`, `family_history_with_overweight`, `FAF`, `TUE`, `CAEC`, `MTRANS`
  * **Engineered**: `BMI`
* **Target**: `NObeyesdad` â€” seven obesity categories from `Insufficient_Weight` to `Obesity_Type_III`.

**Key Cleaning Steps**

* Standardized â€œ?â€ to NaN, coerced numerics, dropped duplicates & nulls.
* Hard bounds:

  * `Age` âˆˆ \[14,â€¯80]
  * `Height` âˆˆ \[1.2â€¯m,â€¯2.2â€¯m]
  * `Weight` âˆˆ \[30â€¯kg,â€¯200â€¯kg]
* IQR filtering on numeric lifestyle features.

---

## ğŸ› ï¸ Modeling Pipeline

1. **Preprocessing**

   * Numeric conversion â†’ Null drop â†’ Outlier filtering â†’ BMI computation
   * Label encode target â†’ Oneâ€‘hot encode categoricals â†’ Train/test split (80/20 stratified)
   * Standard scaling â†’ SMOTE oversampling on training set

2. **Model Training**

   * **Default**: Trained KNN, SVM, XGB with outâ€‘ofâ€‘theâ€‘box hyperparameters.
   * **Tuned**: Grid search (5â€‘fold CV) over relevant hyperparameter grids for each model.

3. **Evaluation**

   * Classification reports (precision, recall, F1â€‘score) on test set.
   * Accuracy summary persisted for â€œAboutâ€ page.

---

## ğŸ§© App Structure

* **`app.py`**
  Main Streamlit script:

  * Loads artifacts: scaler, `feature_columns`, models, label encoder, accuracies, dataset info.
  * Defines `preprocess_input()` to align incoming data with training pipeline.
  * Renders three pages with forms, tables, and download buttons.

* **Artifacts**

  * `scaler.pkl`â€‰â€”â€‰StandardScaler
  * `feature_columns.pkl`â€‰â€”â€‰Ordered list of training features
  * `label_encoder.pkl`â€‰â€”â€‰Target encoder
  * `knn_tuned.pkl`, `svm_tuned.pkl`, `xgb_tuned.pkl`â€‰â€”â€‰Tuned models
  * `accuracy_tuned.pkl`â€‰â€”â€‰Dict of model accuracies
  * `dataset_info.md`â€‰â€”â€‰Dataset overview & cleaning summary

* **`requirements.txt`**
  Lists all Python dependencies.

---

## ğŸš€ Installation & Setup

1. **Clone the repository**

   ```bash
   git clone https://github.com/<yourâ€‘username>/obesityâ€‘classificationâ€‘app.git
   cd obesity-classification-app
   ```

2. **Create & activate virtual environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ Usage

Run the Streamlit app locally:

```bash
streamlit run app.py
```

* Open the provided local URL (e.g. `http://localhost:8501`) in your browser.
* Navigate via the sidebar to explore, predict individually, or run bulk predictions.

---

## ğŸŒ Deployment

To deploy on **Streamlit Cloud** or any other hosting:

1. Push all files (including `.pkl` artifacts and `dataset_info.md`) to your GitHub repo.
2. Connect your repo in Streamlit Cloud.
3. Configure â€œMain fileâ€ as `app.py`.
4. Deploy!

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ app.py
â”œâ”€â”€ dataset_info.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scaler.pkl
â”œâ”€â”€ feature_columns.pkl
â”œâ”€â”€ label_encoder.pkl
â”œâ”€â”€ knn_tuned.pkl
â”œâ”€â”€ svm_tuned.pkl
â”œâ”€â”€ xgb_tuned.pkl
â”œâ”€â”€ accuracy_tuned.pkl
â””â”€â”€ README.md
```
