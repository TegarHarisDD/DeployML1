{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3c0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7960c4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 1. Load & clean data (from previous script)\n",
    "# -------------------------------------------------------------------\n",
    "df = pd.read_csv(\"ObesityDataSet.csv\")\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "numeric_cols = ['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
    "for c in numeric_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df = df[(df['Age'].between(14,80)) &\n",
    "        (df['Height'].between(1.2,2.2)) &\n",
    "        (df['Weight'].between(30,200))]\n",
    "\n",
    "def remove_iqr(df_in, cols):\n",
    "    df_out = df_in.copy()\n",
    "    for c in cols:\n",
    "        q1, q3 = df_out[c].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        lb, ub = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "        df_out = df_out[df_out[c].between(lb, ub)]\n",
    "    return df_out\n",
    "\n",
    "df = remove_iqr(df, ['FCVC','NCP','CH2O','FAF','TUE'])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df['BMI'] = df['Weight'] / df['Height']**2\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['NObeyesdad'] = le.fit_transform(df['NObeyesdad'])\n",
    "\n",
    "cat_cols = ['Gender','CALC','FAVC','SCC','SMOKE',\n",
    "            'family_history_with_overweight','CAEC','MTRANS']\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "X = df.drop('NObeyesdad', axis=1)\n",
    "y = df['NObeyesdad']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "num_feats = ['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE','BMI']\n",
    "X_train[num_feats] = scaler.fit_transform(X_train[num_feats])\n",
    "X_test[num_feats]  = scaler.transform(X_test[num_feats])\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb2574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tegar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:09:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Default ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84        22\n",
      "           1       0.83      0.59      0.69        34\n",
      "           2       0.90      0.88      0.89        42\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       1.00      1.00      1.00        52\n",
      "           5       0.61      0.79      0.69        29\n",
      "           6       0.75      0.68      0.71        31\n",
      "\n",
      "    accuracy                           0.85       248\n",
      "   macro avg       0.83      0.84      0.83       248\n",
      "weighted avg       0.86      0.85      0.85       248\n",
      "\n",
      "=== SVM Default ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        22\n",
      "           1       0.92      0.97      0.94        34\n",
      "           2       0.98      0.95      0.96        42\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       1.00      1.00      1.00        52\n",
      "           5       0.87      0.90      0.88        29\n",
      "           6       0.90      0.90      0.90        31\n",
      "\n",
      "    accuracy                           0.96       248\n",
      "   macro avg       0.95      0.95      0.95       248\n",
      "weighted avg       0.96      0.96      0.96       248\n",
      "\n",
      "=== XGB Default ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        42\n",
      "           3       1.00      1.00      1.00        38\n",
      "           4       1.00      1.00      1.00        52\n",
      "           5       1.00      0.97      0.98        29\n",
      "           6       0.97      1.00      0.98        31\n",
      "\n",
      "    accuracy                           1.00       248\n",
      "   macro avg       1.00      1.00      1.00       248\n",
      "weighted avg       1.00      1.00      1.00       248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 2. Define classifiers (default)\n",
    "# -------------------------------------------------------------------\n",
    "knn_default = KNeighborsClassifier()\n",
    "svm_default = SVC(probability=True, random_state=42)\n",
    "xgb_default = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Train default models\n",
    "# -------------------------------------------------------------------\n",
    "knn_default.fit(X_train_res, y_train_res)\n",
    "svm_default.fit(X_train_res, y_train_res)\n",
    "xgb_default.fit(X_train_res, y_train_res)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 4. Evaluate default models\n",
    "# -------------------------------------------------------------------\n",
    "print(\"=== KNN Default ===\")\n",
    "print(classification_report(y_test, knn_default.predict(X_test)))\n",
    "print(\"=== SVM Default ===\")\n",
    "print(classification_report(y_test, svm_default.predict(X_test)))\n",
    "print(\"=== XGB Default ===\")\n",
    "print(classification_report(y_test, xgb_default.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50783a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KNN Tuned ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        22\n",
      "           1       0.86      0.74      0.79        34\n",
      "           2       0.95      0.95      0.95        42\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       1.00      1.00      1.00        52\n",
      "           5       0.71      0.86      0.78        29\n",
      "           6       0.87      0.84      0.85        31\n",
      "\n",
      "    accuracy                           0.92       248\n",
      "   macro avg       0.91      0.91      0.91       248\n",
      "weighted avg       0.92      0.92      0.92       248\n",
      "\n",
      "Best KNN params: {'n_neighbors': 3, 'p': 1, 'weights': 'distance'}\n",
      "=== SVM Tuned ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       0.97      0.91      0.94        34\n",
      "           2       0.98      1.00      0.99        42\n",
      "           3       1.00      0.97      0.99        38\n",
      "           4       1.00      1.00      1.00        52\n",
      "           5       0.82      0.97      0.89        29\n",
      "           6       1.00      0.90      0.95        31\n",
      "\n",
      "    accuracy                           0.97       248\n",
      "   macro avg       0.97      0.96      0.96       248\n",
      "weighted avg       0.97      0.97      0.97       248\n",
      "\n",
      "Best SVM params: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "=== XGB Tuned ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       1.00      1.00      1.00        34\n",
      "           2       1.00      1.00      1.00        42\n",
      "           3       1.00      1.00      1.00        38\n",
      "           4       1.00      1.00      1.00        52\n",
      "           5       1.00      0.97      0.98        29\n",
      "           6       0.97      1.00      0.98        31\n",
      "\n",
      "    accuracy                           1.00       248\n",
      "   macro avg       1.00      1.00      1.00       248\n",
      "weighted avg       1.00      1.00      1.00       248\n",
      "\n",
      "Best XGB params: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tegar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:09:49] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 5. Hyperparameter grids\n",
    "# -------------------------------------------------------------------\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3,5,7,9],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'p': [1,2]\n",
    "}\n",
    "\n",
    "param_grid_svm = {\n",
    "    'C': [0.1,1,10],\n",
    "    'kernel': ['linear','rbf'],\n",
    "    'gamma': ['scale','auto']\n",
    "}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50,100,200],\n",
    "    'max_depth': [3,5,7],\n",
    "    'learning_rate': [0.01,0.1,0.2]\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 6. GridSearchCV (with 5â€‘fold CV)\n",
    "# -------------------------------------------------------------------\n",
    "gs_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn,\n",
    "                      cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "gs_svm = GridSearchCV(SVC(probability=True, random_state=42), param_grid_svm,\n",
    "                      cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "gs_xgb = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "                      param_grid_xgb, cv=5, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 7. Train tuned models\n",
    "# -------------------------------------------------------------------\n",
    "gs_knn.fit(X_train_res, y_train_res)\n",
    "gs_svm.fit(X_train_res, y_train_res)\n",
    "gs_xgb.fit(X_train_res, y_train_res)\n",
    "\n",
    "knn_tuned = gs_knn.best_estimator_\n",
    "svm_tuned = gs_svm.best_estimator_\n",
    "xgb_tuned = gs_xgb.best_estimator_\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 8. Evaluate tuned models\n",
    "# -------------------------------------------------------------------\n",
    "print(\"=== KNN Tuned ===\")\n",
    "print(classification_report(y_test, knn_tuned.predict(X_test)))\n",
    "print(\"Best KNN params:\", gs_knn.best_params_)\n",
    "print(\"=== SVM Tuned ===\")\n",
    "print(classification_report(y_test, svm_tuned.predict(X_test)))\n",
    "print(\"Best SVM params:\", gs_svm.best_params_)\n",
    "print(\"=== XGB Tuned ===\")\n",
    "print(classification_report(y_test, xgb_tuned.predict(X_test)))\n",
    "print(\"Best XGB params:\", gs_xgb.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f75e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgb_tuned.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Save models - default and tuned versions\n",
    "joblib.dump(knn_default, 'knn_default.pkl')\n",
    "joblib.dump(svm_default, 'svm_default.pkl')\n",
    "joblib.dump(xgb_default, 'xgb_default.pkl')\n",
    "\n",
    "joblib.dump(knn_tuned, 'knn_tuned.pkl')\n",
    "joblib.dump(svm_tuned, 'svm_tuned.pkl')\n",
    "joblib.dump(xgb_tuned, 'xgb_tuned.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5f67ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy reports as strings for Streamlit display\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_default = {\n",
    "    'KNN': accuracy_score(y_test, knn_default.predict(X_test)),\n",
    "    'SVM': accuracy_score(y_test, svm_default.predict(X_test)),\n",
    "    'XGB': accuracy_score(y_test, xgb_default.predict(X_test))\n",
    "}\n",
    "\n",
    "accuracy_tuned = {\n",
    "    'KNN': accuracy_score(y_test, knn_tuned.predict(X_test)),\n",
    "    'SVM': accuracy_score(y_test, svm_tuned.predict(X_test)),\n",
    "    'XGB': accuracy_score(y_test, xgb_tuned.predict(X_test))\n",
    "}\n",
    "\n",
    "joblib.dump(accuracy_default, 'accuracy_default.pkl')\n",
    "joblib.dump(accuracy_tuned, 'accuracy_tuned.pkl')\n",
    "\n",
    "# Save dataset description in a markdown or text file, e.g., 'dataset_info.md'\n",
    "dataset_info = \"\"\"\n",
    "# Dataset Overview\n",
    "- Dataset contains 2111 samples with 17 columns including Age, Gender, Height, Weight, etc.\n",
    "- Target variable is NObeyesdad, categorizing obesity levels.\n",
    "- Data cleaning included removing duplicates, nulls, outliers in Age, Weight, Height.\n",
    "- Feature engineering included BMI calculation.\n",
    "- Encoding categorical variables and normalization applied.\n",
    "\"\"\"\n",
    "with open('dataset_info.md', 'w') as f:\n",
    "    f.write(dataset_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
